<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ZeroSkid – Technical Approach</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header class="site-header">
    <div class="logo">ZeroSkid</div>
    <nav>
      <a href="index.html">Problem & Motivation</a>
      <a href="technical.html" class="active">Technical Approach</a>
    </nav>
  </header>

  <main class="container">
    <section class="card">
      <h1>Technical Approach: AlexNet and Experiments</h1>
      <p>
        This page summarizes the deep learning approach I used for ZeroSkid. I trained AlexNet on my
        wet vs dry road dataset and ran several experiments to see how different hyperparameters
        and architectures affected performance.
      </p>
    </section>

    <section class="card">
      <h2>Model and Preprocessing</h2>
      <ul>
        <li><strong>Base architecture:</strong> AlexNet (pretrained on ImageNet)</li>
        <li><strong>Output classes:</strong> 2 (wet, dry)</li>
        <li><strong>Input size:</strong> 224×224 RGB images</li>
        <li><strong>Preprocessing:</strong> Resize, normalize with ImageNet mean/std</li>
        <li><strong>Augmentation:</strong> Random horizontal flips (for some experiments)</li>
      </ul>
      <p>
        I fine-tuned the final layers of AlexNet so it outputs two classes instead of the original
        1000. The training and validation loops were implemented in PyTorch and logged to
        Weights &amp; Biases (wandb) for tracking metrics and visualizations.
      </p>
    </section>

    <section class="card">
      <h2>Experiments</h2>
      <p>
        I ran five main experiments to study how different choices affect performance:
      </p>
      <ol>
        <li><strong>Experiment 1 – Baseline:</strong> AlexNet, batch size 16, learning rate 0.001, augmentation ON</li>
        <li><strong>Experiment 2 – Batch Size 64:</strong> AlexNet, batch size 64, learning rate 0.001, augmentation ON</li>
        <li><strong>Experiment 3 – Lower Learning Rate:</strong> AlexNet, batch size 16, learning rate 0.0001, augmentation ON</li>
        <li><strong>Experiment 4 – No Augmentation:</strong> AlexNet, batch size 16, learning rate 0.001, augmentation OFF</li>
        <li><strong>Experiment 5 – ResNet18:</strong> ResNet18 instead of AlexNet, batch size 16, learning rate 0.001, augmentation ON</li>
      </ol>
      <p>
        Each experiment logged training/validation accuracy, loss curves, and a confusion matrix
        using wandb.
      </p>
    </section>

    <section class="card">
      <h2>Visualizations</h2>
      <p>
        Below are sample plots and visualizations from the experiments (exported from wandb and
        added as images).
      </p>

      <div class="grid">
        <div class="viz">
          <h3>Baseline Accuracy (Exp 1)</h3>
          <img src="images/exp1_accuracy.png" alt="Experiment 1 accuracy plot" />
        </div>
        <div class="viz">
          <h3>Baseline Loss (Exp 1)</h3>
          <img src="images/exp1_loss.png" alt="Experiment 1 loss plot" />
        </div>
        <div class="viz">
          <h3>Learning Rate 0.0001 (Exp 3)</h3>
          <img src="images/exp3_accuracy.png" alt="Experiment 3 accuracy plot" />
        </div>
        <div class="viz">
          <h3>Confusion Matrix (Best Run)</h3>
          <img src="images/confusion_matrix.png" alt="Confusion matrix for wet vs dry" />
        </div>
      </div>

      <p class="note">
        <strong>Note:</strong> The exact images and filenames are placeholders.
        You can replace them with your own exported plots from wandb.
      </p>
    </section>

    <section class="card">
      <h2>Results and Findings</h2>
      <h3>Baseline (Experiment 1)</h3>
      <p>
        The baseline AlexNet model with batch size 16 and learning rate 0.001 reached around
        <strong>70–75% validation accuracy</strong>. The training loss decreased smoothly, and the
        validation curves showed that the dataset was learnable, even though it is small.
      </p>

      <h3>Batch Size 64 (Experiment 2)</h3>
      <p>
        Increasing the batch size to 64 made training <em>less stable</em>. The loss curves were
        noisier and the validation accuracy did not improve compared to the baseline. This suggests
        that a smaller batch size works better for this dataset because it gives the model more
        frequent updates.
      </p>

      <h3>Lower Learning Rate (Experiment 3)</h3>
      <p>
        Lowering the learning rate to 0.0001 gave some of the <strong>best and most stable
        results</strong>. The training curves were smoother, and the validation accuracy stayed
        consistently around 70%. This experiment showed that a smaller learning rate helped the
        model train more carefully and avoid chaotic updates.
      </p>

      <h3>No Augmentation (Experiment 4)</h3>
      <p>
        When I turned data augmentation off, the model started to
        <strong>overfit</strong> quickly. Training accuracy went up, but validation accuracy got
        worse and the validation loss increased. This confirmed that augmentation was important for
        helping the model generalize beyond the small training set.
      </p>

      <h3>ResNet18 (Experiment 5)</h3>
      <p>
        ResNet18 is a deeper model, and it memorized the training data almost immediately (training
        accuracy reached 100%). However, the validation accuracy stayed around 65–70%, which was not
        much better than AlexNet. This suggests that with such a small dataset, a deeper architecture
        like ResNet18 tends to overfit and does not always give better real-world performance.
      </p>
    </section>

    <section class="card">
      <h2>Takeaways</h2>
      <ul>
        <li>The model can distinguish wet vs dry roads with about <strong>70–75% accuracy</strong>.</li>
        <li>Smaller batch sizes and lower learning rates gave smoother and more reliable training.</li>
        <li>Data augmentation was important for preventing overfitting on the small dataset.</li>
        <li>Deeper models like ResNet18 are not always better when the dataset is limited.</li>
        <li>This project is a good starting point for turning wet road detection into a real safety feature.</li>
      </ul>
    </section>
  </main>

  <footer class="site-footer">
    <p>ZeroSkid – Wet vs Dry Road Detection • 2025</p>
  </footer>
</body>
</html>
