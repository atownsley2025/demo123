<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ZeroSkid ‚Äì Wet vs Dry Road Detection</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header class="site-header">
    <div class="logo">ZeroSkid</div>
    <nav>
      <a href="#problem" class="active">Problem</a>
      <a href="#technical">Technical</a>
      <a href="#experiments">Experiments</a>
      <a href="#takeaways">Takeaways</a>
    </nav>
  </header>

  <main class="container">
    <!-- Hero / Intro -->
    <section class="hero">
      <h1>ZeroSkid: Wet vs Dry Road Classifier</h1>
      <p>
        ZeroSkid is my deep learning project where I trained a model to tell if a road surface is 
        <strong>wet</strong> or <strong>dry</strong> from images. The goal is to explore how computer vision 
        could help warn drivers about unsafe road conditions before they actually lose control.
      </p>
    </section>

    <!-- Problem & Motivation -->
    <section class="card" id="problem">
      <h2>üöó Problem & Motivation</h2>
      <p>
        Hydroplaning can happen really fast, especially when the road looks ‚Äúfine‚Äù but is actually very slick.
        Drivers usually only realize how bad it is once they‚Äôre already losing traction. Most driver-assist
        systems focus on other cars or lane lines, not the actual road surface.
      </p>
      <p>
        My idea with ZeroSkid is to start small: can a model look at an image of the road and figure out if it's
        wet or dry? If that works, it could eventually be part of a bigger safety system that:
      </p>
      <ul>
        <li>Warns the driver when the road looks dangerous</li>
        <li>Automatically adjusts things like cruise control or braking on wet roads</li>
        <li>Helps cars ‚Äúunderstand‚Äù road conditions instead of just traffic</li>
      </ul>
    </section>

    <!-- Dataset -->
    <section class="card">
      <h2>üìÇ Dataset</h2>
      <p>
        I built a small custom dataset with two labels: <strong>wet</strong> and <strong>dry</strong>. 
        The images came from online sources and were organized into folders:
      </p>
      <ul>
        <li><code>train/wet</code>, <code>train/dry</code></li>
        <li><code>valid/wet</code>, <code>valid/dry</code></li>
      </ul>
      <p>
        Every image was resized to <strong>224√ó224</strong> pixels and normalized so that it works well with AlexNet.
        The dataset is pretty small, so part of this project is just seeing how much we can get out of limited data.
      </p>
    </section>

    <!-- Technical Approach -->
    <section class="card" id="technical">
      <h2>üß† Technical Approach (AlexNet)</h2>
      <p>
        I used <strong>PyTorch in Google Colab</strong> and fine-tuned an AlexNet model (originally trained on ImageNet)
        to classify only two classes: wet and dry.
      </p>
      <p>The main steps were:</p>
      <ul>
        <li>Loading the dataset from Google Drive</li>
        <li>Resizing images to 224√ó224 and normalizing with ImageNet mean/std</li>
        <li>Optional data augmentation (random horizontal flips)</li>
        <li>Training AlexNet for multiple runs with different hyperparameters</li>
        <li>Logging everything (loss, accuracy, confusion matrix) to Weights &amp; Biases (wandb)</li>
      </ul>
      <p>
        I also compared AlexNet to <strong>ResNet18</strong> to see how a deeper model behaves on this small dataset.
      </p>
    </section>

    <!-- Experiments & Visualizations -->
    <section class="card" id="experiments">
      <h2>üß™ Experiments & Visualizations</h2>

      <h3>Experiment 1 ‚Äì Baseline AlexNet</h3>
      <p>
        This was my baseline setup:
      </p>
      <ul>
        <li>Batch size: 16</li>
        <li>Learning rate: 0.001</li>
        <li>Augmentation: OFF</li>
      </ul>
      <div class="grid">
        <div class="viz">
          <h3>Accuracy (Exp 1)</h3>
          <img src="images/exp1_accuracy.png" alt="Experiment 1 accuracy plot" />
        </div>
        <div class="viz">
          <h3>Loss (Exp 1)</h3>
          <img src="images/exp1_loss.png" alt="Experiment 1 loss plot" />
        </div>
      </div>

      <h3 style="margin-top:1.4rem;">Experiment 3 ‚Äì Best Performance</h3>
      <p>
        Experiment 3 gave me some of my best results. I changed the learning rate and turned augmentation on:
      </p>
      <ul>
        <li>Learning rate: 0.0001</li>
        <li>Batch size: 16</li>
        <li>Augmentation: ON</li>
      </ul>

      <div class="grid">
        <div class="viz">
          <h3>Accuracy (Exp 3)</h3>
          <img src="images/exp3_accuracy.png" alt="Experiment 3 accuracy plot" />
        </div>
        <div class="viz">
          <h3>Loss (Exp 3)</h3>
          <img src="images/exp3_loss.png" alt="Experiment 3 loss plot" />
        </div>
      </div>

      <h3 style="margin-top:1.4rem;">Confusion Matrix (Best Model)</h3>
      <p>
        This confusion matrix is from one of the stronger runs:
      </p>
      <img src="images/confusion_matrix.png" alt="Confusion matrix for wet vs dry predictions" />

      <p class="note">
        The model is very good at recognizing <strong>wet</strong> roads, but it sometimes predicts ‚Äúwet‚Äù when the road
        is actually dry. For a safety tool, that‚Äôs not the worst problem, because it‚Äôs better to be overly cautious than
        to miss a truly wet road.
      </p>
    </section>

    <!-- Takeaways -->
    <section class="card" id="takeaways">
      <h2>üìå Takeaways</h2>
      <ul>
        <li>AlexNet can learn the difference between wet and dry roads even with a small dataset.</li>
        <li>Lowering the learning rate and using data augmentation gave smoother training and better validation accuracy.</li>
        <li>Turning augmentation off made the model overfit faster (training accuracy high, validation worse).</li>
        <li>ResNet18 is more powerful, but with this small dataset it can overfit and doesn‚Äôt always beat AlexNet by a lot.</li>
        <li>The model leans toward predicting ‚Äúwet,‚Äù which is actually safer for a real-world warning system.</li>
      </ul>
      <p style="margin-top:0.6rem;">
        Overall, this project is an early step toward the bigger ZeroSkid idea: using AI to help drivers understand
        road conditions before they become a problem.
      </p>
    </section>
  </main>

  <footer class="site-footer">
    <p>ZeroSkid ‚Äì Wet vs Dry Road Detection ‚Ä¢ demo123 GitHub repo</p>
  </footer>
</body>
</html>
